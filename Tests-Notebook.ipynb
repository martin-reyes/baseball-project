{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18edb407",
   "metadata": {},
   "source": [
    "This notebook serves to be where we test code for any step of the data pipeline (Acquire, Clean, Explore, test/model, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82492ba",
   "metadata": {},
   "source": [
    "If we want to later have a cleaner notebook of our findings, viz's, conclusions, etc., we can make another notebook called something like `report.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8f2de7",
   "metadata": {},
   "source": [
    "Import below. Make a small comment on what import is for if the import isn't a common library/module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6afa697f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "381cf85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b0f6394",
   "metadata": {},
   "outputs": [],
   "source": [
    "import acquire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f01214",
   "metadata": {},
   "source": [
    "## Acquire data\n",
    "\n",
    "Data from [Baseball Reference](https://www.baseball-reference.com)\n",
    "\n",
    "\n",
    "Use this area to test code that will help you write data acquisition funnctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a444f8a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b070e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6481155b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95031aaa",
   "metadata": {},
   "source": [
    "## Clean/Wrangle data\n",
    "\n",
    "Test code to clean data. If you want to clean the data a certain way later on for a certain ML model or stats test, you can come back to this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ce0d63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea73d36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacf959f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5312b118",
   "metadata": {},
   "source": [
    "## Explore data (EDA)\n",
    "\n",
    "Test code to explore data. Analyze and make visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce0b286",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3940250",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros_like(df.corr())\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "with sns.axes_style(\"white\"):\n",
    "    f, ax = plt.subplots(figsize=(14, 8))\n",
    "    ax = sns.heatmap(df.corr(), mask=mask, cmap='coolwarm',\n",
    "                     linewidths=.5, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809495cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23da3612",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d553931f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609b9294",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6a94e1d",
   "metadata": {},
   "source": [
    "## Tests\n",
    "\n",
    "Test code here if you want to run stats tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd00e499",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89e595e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225e01a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983db25e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96e3b597",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "Test code here if you want to run ML models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229e8bed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86050567",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e27040",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef0fe6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3579cb0",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45f4a48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecfb55f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b6aeb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e27d2e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedee21a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a66c54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e9ebc7c",
   "metadata": {},
   "source": [
    "<div style=\"border: 5px solid black;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f665d622",
   "metadata": {},
   "source": [
    "Published Functions\n",
    "\n",
    "Use this section to refer to published functions. Feel free to copy them to either improve them, or come up. with new ideas and functions. **Don't edit**\n",
    "\n",
    "#### `Acquire.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdbadf6",
   "metadata": {},
   "source": [
    "Function to store tables read on a website to pandas DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0d7e30a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_website_tables(url, webdriver_path = '~/chromedriver'):\n",
    "    \"\"\"\n",
    "        reads tables from a url and returns them as DataFrames\n",
    "    \n",
    "        necessary imports:\n",
    "        import pandas as pd\n",
    "        from bs4 import BeautifulSoup\n",
    "        from selenium import webdriver\n",
    "        from selenium.webdriver.chrome.service import Service\n",
    "        from selenium.webdriver.common.by import By\n",
    "        from selenium.webdriver.chrome.options import Options\n",
    "        from selenium.webdriver.common.action_chains import ActionChains\n",
    "        from selenium.webdriver.common.keys import Keys\n",
    "    \"\"\"\n",
    "    # Path to chromedriver executable\n",
    "    webdriver_path = webdriver_path\n",
    "\n",
    "    # Set up the Selenium driver with options\n",
    "    options = Options()\n",
    "    options.add_argument('--headless')  # Run in headless mode\n",
    "    driver = webdriver.Chrome(service=Service(webdriver_path), options=options)\n",
    "\n",
    "    # Load the webpage\n",
    "    driver.get(url)\n",
    "\n",
    "    # Wait for the dynamic content to load (if necessary)\n",
    "    # You can use driver.implicitly_wait() or other wait methods\n",
    "\n",
    "    # Extract the page source after the dynamic content has loaded\n",
    "    source = driver.page_source\n",
    "\n",
    "    # Close the Selenium driver\n",
    "    driver.quit()\n",
    "\n",
    "    # Parse the page source with BeautifulSoup\n",
    "    soup = BeautifulSoup(source, 'lxml')\n",
    "\n",
    "    # Find all the table elements\n",
    "    table_elements = soup.find_all('table')\n",
    "\n",
    "    # Extract the HTML content from each table element\n",
    "    html_tables = [str(table) for table in table_elements]\n",
    "\n",
    "    # Pass the list of HTML tables to pd.read_html()\n",
    "    dfs = pd.read_html('\\n'.join(html_tables))\n",
    "    \n",
    "    return dfs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1c582b",
   "metadata": {},
   "source": [
    "Save data. Pass in df and specify file name (without extension)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8072c926",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(df, filename):\n",
    "    \"\"\"\n",
    "        save DataFrame to csv file\n",
    "    \"\"\"\n",
    "    df.to_csv(f'{filename}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad98e5e",
   "metadata": {},
   "source": [
    "Gets team acronyms and puts them into a list. List can be useful for things like navigating team url's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09a4ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mlb_acronyms():\n",
    "    \n",
    "    url = 'https://www.baseball-reference.com'\n",
    "    source = requests.get(url).text # html of website\n",
    "    \n",
    "    soup = BeautifulSoup(source, 'lxml')\n",
    "    \n",
    "    # All team acronyms are in the first `div` tag with  \n",
    "    # class = \"formfield\". They are then in option tags (except the first).\n",
    "    #     print(soup)\n",
    "    #     print(soup.find_all('div', class_='formfield')[0])\n",
    "    #     print(len(soup.find_all('div', class_='formfield')[0]))\n",
    "    div_formfield = soup.find_all('div', class_='formfield')[0]\n",
    "    option_tags = div_formfield.find_all('option')[1:]\n",
    "    \n",
    "    # Should be 30 acronyms\n",
    "    team_acronyms = [str(tag)[15:18] for tag in option_tags]\n",
    "\n",
    "    return team_acronyms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab02a037",
   "metadata": {},
   "source": [
    "Gets team stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba55183d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_team_stats(start_year=2015, end_year=2022, \n",
    "                   bat_or_pitch='batting', measures=['standard'], full_seasons_only = True):\n",
    "    \"\"\"\n",
    "        Reads and stores team batting or pitching stats from start_year to end_year.\n",
    "        Can't merge pre-2015 data to 2015-present data because there are 2 new stats for post-2014 years\n",
    "        Batting measures: standard, advanced, sabermetric\n",
    "        Pitching measures: standard, advanced, batting (against), ratio\n",
    "        Returns pandas DataFrame.\n",
    "    \"\"\"\n",
    "    # for each year\n",
    "    for year in range(start_year, end_year+1):\n",
    "        # skip non-full-seasons\n",
    "        if year in [2020, 2023]:\n",
    "            continue   \n",
    "        \n",
    "        if bat_or_pitch == 'batting':\n",
    "            # get Win-Loss records\n",
    "            url = f'https://www.baseball-reference.com/leagues/majors/{year}-standard-pitching.shtml'\n",
    "            w_l_records = read_website_tables(url, webdriver_path = '~/chromedriver')[0][:30][['W','L','W-L%']] \n",
    "\n",
    "        # get stats by measure\n",
    "        measure_dfs =[]\n",
    "        for measure in measures:\n",
    "            # read and store team stats table for given year. 2 tables are on this url with the first being team stats\n",
    "            url = f'https://www.baseball-reference.com/leagues/majors/{year}-{measure}-{bat_or_pitch}.shtml'\n",
    "            measure_df = read_website_tables(url, webdriver_path = '~/chromedriver')[0][:30]\n",
    "\n",
    "            if measure == 'advanced':\n",
    "                measure_df.columns = [col[1] for col in measure_df.columns]\n",
    "            \n",
    "            measure_dfs.append(measure_df)\n",
    "        \n",
    "        # join tables to get stats for the year\n",
    "        year_stats = pd.concat(measure_dfs, axis=1)\n",
    "        \n",
    "        # add year column\n",
    "        year_stats['year'] = year\n",
    "#         # move column to be first\n",
    "#         cols = list(year_stats.columns)\n",
    "#         cols.insert(0, cols.pop(cols.index('year')))\n",
    "#         year_stats = year_stats[cols]\n",
    "        \n",
    "        # if team_stats df exists, add year_stats to team_stats\n",
    "        if 'team_stats' in locals():\n",
    "            team_stats = pd.concat([team_stats, year_stats])\n",
    "        # else initialize it\n",
    "        else:\n",
    "            team_stats = year_stats\n",
    "        \n",
    "    return team_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d81672",
   "metadata": {},
   "source": [
    "Read and stores player IDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a91334f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_player_ids(url, webdriver_path = '~/chromedriver'):\n",
    "    \"\"\"\n",
    "        reads player ID's from a url and returns these ID's in a list of strings\n",
    "    \"\"\"\n",
    "    # Path to chromedriver executable\n",
    "    webdriver_path = webdriver_path\n",
    "\n",
    "    # Set up the Selenium driver with options\n",
    "    options = Options()\n",
    "    options.add_argument('--headless')  # Run in headless mode\n",
    "    driver = webdriver.Chrome(service=Service(webdriver_path), options=options)\n",
    "    \n",
    "    # Load the webpage\n",
    "    driver.get(url)\n",
    "\n",
    "    # Wait for the dynamic content to load (if necessary)\n",
    "    # You can use driver.implicitly_wait() or other wait methods\n",
    "\n",
    "    # Extract the page source after the dynamic content has loaded\n",
    "    source = driver.page_source\n",
    "\n",
    "    # Close the Selenium driver\n",
    "    driver.quit()\n",
    "\n",
    "    # Parse the page source with BeautifulSoup\n",
    "    soup = BeautifulSoup(source, 'lxml')\n",
    "\n",
    "    # Find all the table elements\n",
    "    table_elements = soup.find_all('table')\n",
    "\n",
    "    # Second table in url has player_stats\n",
    "    player_table = table_elements[1]\n",
    "    \n",
    "    # player IDs are in 'data-append-csv' attribute of 'td' tags that have 'data-stat = player'\n",
    "    # emit last ID, which is blank\n",
    "    player_ids = [tag.get('data-append-csv')\n",
    "                 for tag in player_table.find_all('td', attrs={'data-stat': 'player'})][:-1]\n",
    "    \n",
    "    return player_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1bc58a",
   "metadata": {},
   "source": [
    "<div style=\"border: 5px solid black;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af3b601",
   "metadata": {},
   "source": [
    "#### Web Scrape\n",
    "\n",
    "- If you want to try to grab tables with advanced stats, you can use BeautifulSoup, requests, and/or pandas to read the tables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514dd6f3",
   "metadata": {},
   "source": [
    "Basic pitching stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8eeeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_team_pitching_stats(start_year = 2010, end_year = 2023, full_seasons_only=True):\n",
    "    \n",
    "    for year in range(start_year, end_year + 1):\n",
    "        \n",
    "        # skip non-full seasons\n",
    "        if full_seasons_only:\n",
    "            if year == 2023 or year == 2020:\n",
    "                continue\n",
    "        \n",
    "        # read url with pandas\n",
    "        url = f'https://www.baseball-reference.com/leagues/majors/{year}-standard-pitching.shtml'\n",
    "        temp_df = pd.read_html(url)[0].iloc[:30,:]\n",
    "        \n",
    "        # create year column\n",
    "        temp_df['year'] = year\n",
    "        \n",
    "        # if first year, start batting_df with temp_df, or else concat temp_df to batting_df\n",
    "        if year == start_year:\n",
    "            team_pitching_stats = temp_df\n",
    "        else:\n",
    "            team_pitching_stats = pd.concat([team_pitching_stats, temp_df])\n",
    "    \n",
    "    \n",
    "    return team_pitching_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf841fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pitching_df = get_pitching_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bc7443",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pitching_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d537c7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f84514f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97588537",
   "metadata": {},
   "source": [
    "Potential urls to scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e08523",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    batting_url = f'https://www.baseball-reference.com/teams/{team}/{year}-{bat_pit_field}.shtml'\n",
    "'''\n",
    "\n",
    "'''https://baseballsavant.mlb.com/leaderboard/custom?\n",
    "            year=2022,2021,2020,2019,2018,2017,2016,2015,2014\n",
    "            &type=batter&filter=&sort=0&sortDir=asc&min=q\n",
    "            &selections=player_age,b_ab,b_total_pa,b_total_hits,b_single,b_double,b_triple,\n",
    "            b_home_run,b_strikeout,b_walk,b_k_percent,b_bb_percent,batting_avg,slg_percent,\n",
    "            on_base_percent,on_base_plus_slg,isolated_power,b_rbi,b_lob,b_total_bases,r_total_caught_stealing,\n",
    "            r_total_stolen_base,b_ab_scoring,b_ball,b_called_strike,b_catcher_interf,b_foul,b_foul_tip,b_game,\n",
    "            b_gnd_into_dp,b_gnd_into_tp,b_gnd_rule_double,b_hit_by_pitch,b_hit_ground,b_hit_fly,b_hit_into_play,\n",
    "            b_hit_line_drive,b_hit_popup,b_out_fly,b_out_ground,b_out_line_drive,b_out_popup,b_intent_ball,\n",
    "            b_intent_walk,b_interference,b_pinch_hit,b_pinch_run,b_pitchout,b_played_dh,b_sac_bunt,b_sac_fly,\n",
    "            b_swinging_strike,r_caught_stealing_2b,r_caught_stealing_3b,r_caught_stealing_home,r_defensive_indiff,\n",
    "            r_interference,r_pickoff_1b,r_pickoff_2b,r_pickoff_3b,r_run,r_stolen_base_2b,r_stolen_base_3b,\n",
    "            r_stolen_base_home,b_total_ball,b_total_sacrifices,b_total_strike,b_total_swinging_strike,b_total_pitches,\n",
    "            r_stolen_base_pct,r_total_pickoff,b_reached_on_error,b_walkoff,b_reached_on_int,xba,xslg,woba,xwoba,xobp,\n",
    "            xiso,wobacon,xwobacon,bacon,xbacon,xbadiff,xslgdiff,wobadiff,exit_velocity_avg,launch_angle_avg,\n",
    "            sweet_spot_percent,barrel,barrel_batted_rate,solidcontact_percent,flareburner_percent,poorlyunder_percent,\n",
    "            poorlytopped_percent,poorlyweak_percent,hard_hit_percent,avg_best_speed,avg_hyper_speed,\n",
    "            &chart=false&x=xba&y=xba&r=no&chartType=beeswarm'''\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4941ea93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
